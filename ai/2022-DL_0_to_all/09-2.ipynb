{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f3fdf4-92fc-4936-ae43-504bb823a087",
   "metadata": {},
   "source": [
    "# Lab-09-2 Weight Initialization\n",
    "\n",
    "- Why good initialization?\n",
    "- RBM / DBN\n",
    "- Xavier / He initialization\n",
    "- Code: mnist_nn_xavier\n",
    "- Code: mnist_nn_deep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e969bd56-3270-4def-b7d8-b1de6b545eb1",
   "metadata": {},
   "source": [
    "## Need to set the initial weight values wisely\n",
    "\n",
    "- Not all 0's\n",
    "- Challenging issue\n",
    "- Hinton et al. (2006) \"A Fast Learning Algorithm for Deep Belief Nets\" -  Restricted Boltzmann Machine (RBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31c8aa-ab18-48c5-85ff-06624cff87e1",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine\n",
    "\n",
    "- Restricted: no connections within a layer (한 레이어 안에 있는 노드들 간에는 연결이 없다. 다만 다른 레이어의 노드들에는 fully-connected인 것을 RBM이라 함.)\n",
    "- KL divergence: compare actual to recreation\n",
    "\n",
    "이런 머신이 있으면 어떤 입력 x가 들어갔을 때 y를 만들 수 있는 forward가 있고, 또 y -> x 복원하는 backward, encoding/decoding과 같은 것이 가능."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a5ca30-d618-4644-8b7c-5b13b271d648",
   "metadata": {},
   "source": [
    "## How can we use RBM to initialize weights?\n",
    "\n",
    "- Apply the RBM idea on adjacent two layers as a <u>pre-training</u> step (힌튼 교수님이 pre-training이라는 방법 소개)\n",
    "- Continue the first process to all layers\n",
    "- This will set weights\n",
    "- Example: Deep Belief Network\n",
    "    - Weight initialized by RBM\n",
    "\n",
    "## Deep Belief Network\n",
    "\n",
    "- Pre-training (x - h^1 - h^2 - ...)\n",
    "    1. layer 1 <-> layer 2 간 RBM으로 w 학습 (RBM for x)\n",
    "    2. layer 2 <-> layer 3 간 RBM으로 w 학습 (RBM for h^1)\n",
    "    3. layer 3 <-> layer 4 간 RBM으로 w 학습 (RBM for h^2)\n",
    "    4. ... 마지막까지 하면 마무리\n",
    "    \n",
    "- Fine-tuning\n",
    "    - Pre-training 마무리되면 RBM으로 모든 레이어 weight 학습되었을 것.\n",
    "    - 그 weight 전체 두고 뉴럴 네트워크 학습해서 y 구하고 G와의 차이 구해서 loss 구해서 back prop -> 네트워크 update 다시 한번 하는데 이걸 fine-tuning 단계라 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747bd1d4-727f-4ca3-9881-e1965f90d842",
   "metadata": {},
   "source": [
    "## Xavier / He initialization\n",
    "\n",
    "- RBM은 요새 잘 안씀\n",
    "\n",
    "- No need to use complicated RBM for weight initializations\n",
    "- Simple methods are OK\n",
    "    - **Xavier initialization**: X. Glorot and Y. Bengio, \"Understanding the difficulty of training deep feedforward neural networks,\" in International conference on artificial intelligence and statistics, 2010\n",
    "    - **He initialization**: K. He, X. Zhang, S. Ren, and J. Sun, \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification,\" 2015\n",
    "    \n",
    "레이어 특성에 따라 initialzation 따로 해야 한다.\n",
    "\n",
    "Xavier: RBM보다 덜 복잡함. pre-training/fine-tuning 필요 없음.\n",
    "- Xavier Normal initialization\n",
    "    - $W \\sim N(0, Var(W))$\n",
    "    - $Var(W) = \\sqrt{\\frac{2}{n_{in} + n_{out}}}$\n",
    "- Xavier Uniform initialization\n",
    "    - $W \\sim U(-\\sqrt{-\\frac{6}{n_{in} + n_{out}}}, +\\sqrt{\\frac{6}{n_{in} + n_{out}}})$\n",
    "    \n",
    "He: Xavier의 변형. 수식의 형태도 굉장히 비슷함.\n",
    "- He Normal initialzation\n",
    "    - $W \\sim N(0, Var(W))$\n",
    "    - $Var(W) = \\sqrt{\\frac{2}{n_{in}}}$\n",
    "- He Uniform initialization\n",
    "    - $W \\sim U(-\\sqrt{\\frac{6}{n_{in}}}, +\\sqrt{\\frac{6}{n_{in}}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eadf84-d124-4d2c-a2c5-12c4c72c1193",
   "metadata": {},
   "source": [
    "## Code: mnist_nn_xavier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6fd19-0dbf-4200-be3d-9efa9a7fee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_uniform_(tensor, gain=1):\n",
    "    \"\"\"\n",
    "    .. math::\n",
    "        a = \\text{gain} \\times \\sqrt{\\frac{6}{\\text{fan_in} + \\text{fan_out}}}\n",
    "    \n",
    "    Also known as Glorot initialization.\n",
    "    \n",
    "    Args:\n",
    "        tensor: an n-dimensional `torch.Tensor`\n",
    "        gain: an optional scaling factor\n",
    "    \n",
    "    Examples:\n",
    "        >>> w = torch.empty(3, 5)\n",
    "        >>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))\n",
    "    \"\"\"\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n",
    "    std = gain * math.sqrt(2.0 / (fan_in + fan_out))\n",
    "    a = math.sqrt(3.0) * std   # Calculate uniform bounds from standard deviation\n",
    "    with torch.no_grad():\n",
    "        return tensor.uniform_(-a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd96734-bbd2-4405-acf8-fa8b24223bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# nn layers\n",
    "linear1 = torch.nn.Linear(784, 256, bias=True)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "# xavier initialization\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8422f7b7-901b-4629-895a-5a88bd209cee",
   "metadata": {},
   "source": [
    "weight 초기화만 바꿔도 굉장히 성능 빨라짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9230567-708e-4b32-b303-5e16e956aab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
