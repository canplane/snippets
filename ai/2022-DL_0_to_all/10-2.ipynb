{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c8edc7c-72a3-4aa5-a981-92c75e87b5ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 오늘은\n",
    "- MNIST에 CNN 적용해보기\n",
    "    1. 딥러닝을 학습시키는 단계\n",
    "    2. 우리가 만들 CNN 구조 확인\n",
    "    3. MNIST에 CNN 적용 코드를 함께 작성\n",
    "    \n",
    "## 학습 단계(code 기준)\n",
    "1. 라이브러리 가져오고 (torch, torchvision, matplotlib 같은 것들)\n",
    "2. GPU 사용 설정하고 random value를 위한 seed 설정!\n",
    "3. 학습에 사용되는 parameter 설정! (learning_rate, training_epochs, batch_size, etc)\n",
    "4. 데이터셋을 가져오고 (학습에 쓰기 편하게) loader 만들기\n",
    "5. 학습 모델 만들기 (class CNN(torch.nn.Module))\n",
    "6. Loss function (Criterion)을 선택하고 최적화 도구 선택(optimizer)\n",
    "7. 모델 학습 및 loss check(Criterion의 output)\n",
    "8. 학습된 모델의 성능을 확인한다.\n",
    "\n",
    "\n",
    "![snapshot](./10-2-0.png)\n",
    "\n",
    "- (Layer 1) Convolution layer = (in_c=1, out_c=32, kernel_size=3, stride=1, padding=1)\n",
    "- (Layer 1) MaxPool layer = (kernel_size=2, stride=2)\n",
    "- (Layer 2) Convolution layer = (in_c=32, out_c=64, kernel_size=3, stride=1, padding=1)\n",
    "- (Layer 2) MaxPool layer = (kernel_size=2, stride=2)\n",
    "- view => (batch_size x [7,7,64] => batch_size x [3136])\n",
    "- Fully_Connect layer => (input=3136, output=10)\n",
    "\n",
    "view라는 건 사실 레이어로 존재하진 않지만 이해의 편의를 위해 넣어둠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d706ee50-feb9-4d01-b237-53d2d2bf9892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "inputs = torch.Tensor(1, 1, 28, 28)   # batch, channel, height, width\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62fcc735-e32a-4e9a-9f54-65e1ddc3071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)   # 1채널 in, 32채널 out, 커널 사이즈 3, 패딩 1\n",
    "conv2 = nn.Conv2d(32, 64, 3, padding=1)  # stride 기본값은 1이므로 지정할 필요 X\n",
    "pool = nn.MaxPool2d(2)   # max pooling은 똑같은 역할 담당하므로 하나만 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ada59c9b-ca57-477d-9d73-b544bcdc4073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "                 (height - kernel) + 2 * padding       (28 - 3) + 2 * 1\n",
    "    new_height = ------------------------------- + 1 = ---------------- + 1 = 28\n",
    "                              stride                           1\n",
    "'''\n",
    "\n",
    "out = conv1(inputs)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07cc0327-09bc-4802-9d74-2c1b772bd06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 14, 14])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "                 height   28\n",
    "    new_height = ------ = -- = 14\n",
    "                 kernel    2\n",
    "'''\n",
    "\n",
    "out = pool(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259fb8c8-9517-4a6b-87b9-27d6a8f9318f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 14, 14])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = conv2(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f5ea0c-ff6d-4fb1-b1cd-1556dc3303fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 7, 7])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pool(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c823d41c-ad5d-4907-b9e1-6c53c2657078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 64 7 7\n"
     ]
    }
   ],
   "source": [
    "# [1, 32, 14, 14]에서 각 위치에 해당하는 값 리턴하는 코드\n",
    "\n",
    "print(out.size(0), out.size(1), out.size(2), out.size(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec236b0-1460-4ef5-a894-c83079845b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3136])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64 * 7 * 7 = 3136\n",
    "\n",
    "out = out.view(out.size(0), -1)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0acb58d-53df-48b3-afa6-49689661de65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in이 3136, out이 10인 fully-connected layer 만들기\n",
    "\n",
    "fc = nn.Linear(3136, 10)\n",
    "out = fc(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe622f8-6d91-4a66-b966-85b4e588a418",
   "metadata": {},
   "source": [
    "... 대충 이러한 방식\n",
    "\n",
    "\n",
    "## MNIST에 CNN 적용 코드를 함께 작성\n",
    "- jupyter notebook을 켜고 직접 같이 쳐보면서 진행하겠습니다.\n",
    "- 그럼 시작해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e12041e3-b07b-40c4-8294-e842d7ea8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 초기 라이브러리 불러오기\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba3d0dd2-4fa4-4a51-8e2b-333213b5873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GPU 설정, random value를 위한 seed 설정\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(777)    # random value 고정해주는 코드\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cb8ff28-a037-47d9-ab39-e5a7d01a977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu False\n"
     ]
    }
   ],
   "source": [
    "print(device, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a3b4649-2f30-456b-8943-592c55cb9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 학습에 사용하는 파라미터 설정\n",
    "# 배포하는 코드에는 여기에 파라미터를 작성하는 걸로 되어 있는데, 사실 파라미터는 나중에 써도 상관없음.\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d9aeb5-b379-42a3-9d73-5799d400cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 데이터셋 가져오고,\n",
    "# MNIST dataset\n",
    "\n",
    "mnist_train = dsets.MNIST(root=\"MNIST_data/\",\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "# transform : input 데이터를 어떻게 변환해 줄거냐?\n",
    "# 그냥 받아왔을 때는 tensor value가 아님. 그러니 MNIST data를 텐서 밸류로 변환해주는 역할\n",
    "mnist_test = dsets.MNIST(root=\"MNIST_data/\",\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5fa59c8-7ef7-4919-9c8d-21490847835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. (학습에 쓰기 편하게) 데이터 loader 만들기\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,  # 데이터를 섞은 상태로 던져줘라\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cfab1f7-11ae-4c1f-9ea8-58d47fa6ea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. CNN이라는 학습 모델 만들기\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()  # 이거 절대 빼먹으면 안됨. 빼먹으면 학습이 전혀 안된다.\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(7*7*64, 10, bias=True)   # 0-9가 10개니까\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        # view로 펼치기. 배치 사이즈만큼 펼치고, 나머지는 한 줄로.\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95c01a76-be0d-476b-85b5-431baef1527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73ffedb4-f944-47ab-a6ec-3c050023b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   # Adam optimizer 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90e791aa-de40-4296-b1bf-59f6acd6918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1] cost = 0.22519506514072418\n",
      "[Epoch:2] cost = 0.059969183057546616\n",
      "[Epoch:3] cost = 0.04360518231987953\n",
      "[Epoch:4] cost = 0.03506407514214516\n",
      "[Epoch:5] cost = 0.02890731394290924\n",
      "[Epoch:6] cost = 0.024456340819597244\n",
      "[Epoch:7] cost = 0.02169337309896946\n",
      "[Epoch:8] cost = 0.017144329845905304\n",
      "[Epoch:9] cost = 0.014846979640424252\n",
      "[Epoch:10] cost = 0.012522861361503601\n",
      "[Epoch:11] cost = 0.010015181265771389\n",
      "[Epoch:12] cost = 0.010326125659048557\n",
      "[Epoch:13] cost = 0.007664399221539497\n",
      "[Epoch:14] cost = 0.006844808347523212\n",
      "[Epoch:15] cost = 0.005508054979145527\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:   # (image, label)\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        # cuda 연산을 진행하려면 torch.tensor가 아니라 torch.cuda_tensor가 되어 있어야 함\n",
    "        \n",
    "        optimizer.zero_grad()   # 이거 빼먹으면 학습이 아예 안됨\n",
    "        hypothesis = model(X)  # model에다가 input 값 넣어서 그 출력값이 가설이 되겠지\n",
    "        \n",
    "        cost = criterion(hypothesis, Y)  # 가설과 실제 라벨 사이의 차이를 계산하는 loss. cross entropy로 계산을 한다.\n",
    "        cost.backward()   # 그리고 그 cost 값을 backward를 해주고.\n",
    "        optimizer.step()   # optimizer가 그 값을 토대로 학습을 진행함.\n",
    "        \n",
    "        avg_cost += cost / total_batch    # 그 다음에 average cost 계산해서 쌓아준다.\n",
    "        \n",
    "    # 한 epoch이 끝나면 epoch에 대해서 cost가 몇이었는지 확인을 하면 됨\n",
    "    print(\"[Epoch:{}] cost = {}\".format(epoch + 1, avg_cost))\n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87f6cf8b-c69f-4120-bb60-f59675ca3e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghoon/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9883000254631042\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    # 한번에 집어넣으려고 쫙 펼쳤다고 생각하면 된다.\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c974d06-2aeb-46ab-8866-5090c863dc2d",
   "metadata": {},
   "source": [
    "## 우리가 확인한 결과\n",
    "- 더 깊게 레이어를 쌓으면 어떻게 될까?\n",
    "- 더 잘 되지 않을까? (위의 것은 98.5%)\n",
    "\n",
    "- 더 추가하자! (Layer 3, Layer 4, 5) (NLL: negative log-likelihood)\n",
    "![snapshot](./10-2-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f69e7761-9f8f-43e1-8bda-c9feed6bd457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()  # 이거 절대 빼먹으면 안됨. 빼먹으면 학습이 전혀 안된다.\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        ########\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        # 7을 maxpool(2)하면 3, 출력은 128\n",
    "        self.fc1 = nn.Linear(3*3*128, 625)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(625, 10, bias=True)   # 0-9가 10개니까\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        ########\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        # view로 펼치기. 배치 사이즈만큼 펼치고, 나머지는 한 줄로.\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "# model을 만들면 테스트를 해봐야 한다.\n",
    "value = torch.Tensor(1, 1, 28, 28).to(device)\n",
    "print( (model(value)).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7b7cc0d-f61c-41f1-8564-6d63ba353c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1] cost = 0.15921327471733093\n",
      "[Epoch:2] cost = 0.04140569642186165\n",
      "[Epoch:3] cost = 0.028637103736400604\n",
      "[Epoch:4] cost = 0.021885210648179054\n",
      "[Epoch:5] cost = 0.01738460548222065\n",
      "[Epoch:6] cost = 0.014934803359210491\n",
      "[Epoch:7] cost = 0.012485607527196407\n",
      "[Epoch:8] cost = 0.011487196199595928\n",
      "[Epoch:9] cost = 0.010386358015239239\n",
      "[Epoch:10] cost = 0.0076933130621910095\n",
      "[Epoch:11] cost = 0.005744565278291702\n",
      "[Epoch:12] cost = 0.006951894611120224\n",
      "[Epoch:13] cost = 0.004991516470909119\n",
      "[Epoch:14] cost = 0.006859457585960627\n",
      "[Epoch:15] cost = 0.005690425168722868\n",
      "Learning Finished!\n",
      "Accuracy: 0.9876999855041504\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)   # Adam optimizer 사용\n",
    "\n",
    "# Training\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:   # (image, label)\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        # cuda 연산을 진행하려면 torch.tensor가 아니라 torch.cuda_tensor가 되어 있어야 함\n",
    "        \n",
    "        optimizer.zero_grad()   # 이거 빼먹으면 학습이 아예 안됨\n",
    "        hypothesis = model(X)  # model에다가 input 값 넣어서 그 출력값이 가설이 되겠지\n",
    "        \n",
    "        cost = criterion(hypothesis, Y)  # 가설과 실제 라벨 사이의 차이를 계산하는 loss. cross entropy로 계산을 한다.\n",
    "        cost.backward()   # 그리고 그 cost 값을 backward를 해주고.\n",
    "        optimizer.step()   # optimizer가 그 값을 토대로 학습을 진행함.\n",
    "        \n",
    "        avg_cost += cost / total_batch    # 그 다음에 average cost 계산해서 쌓아준다.\n",
    "        \n",
    "    # 한 epoch이 끝나면 epoch에 대해서 cost가 몇이었는지 확인을 하면 됨\n",
    "    print(\"[Epoch:{}] cost = {}\".format(epoch + 1, avg_cost))\n",
    "print(\"Learning Finished!\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    # 한번에 집어넣으려고 쫙 펼쳤다고 생각하면 된다.\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7df42-a526-46fe-b4fc-be2e126daaaf",
   "metadata": {},
   "source": [
    "**오히려 아까보다 accuracy가 떨어짐!** (98% -> 97%)\n",
    "\n",
    "모델을 쌓을 때는 깊게 쌓는 것도 중요하지만, 얼마나 효율적으로 쌓는지가 더 중요하다는 것도 생각하면서 쌓아보면 좋을 것이다.\n",
    "\n",
    "이후에 배울 굉장히 다양한 아키텍처들. 언급 드리고 몇 가지는 이런 식으로 일일이 만들어 볼 건데, 그 과정을 거치면서 수많은 연구자들이 어떻게 효율적인 아키텍처를 구성했는가? 그리고 요즘에는 어떤 방식으로 사용하고 있는가까지 공부해 보면 좋을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809389e-4bd2-4bcc-9519-8bfce4d04abe",
   "metadata": {},
   "source": [
    "## 오늘 같이 해본 것들은?\n",
    "1. 딥러닝을 학습시키는 단계를 복습!\n",
    "2. 우리가 만들 CNN 구조 확인!\n",
    "3. 필요한 함수들의 사용 방법을 확인\n",
    "4. MNIST에 CNN 적용 코드를 함께 작성\n",
    "\n",
    "## What's Next?\n",
    "- 모델을 조금 더 깊게 만들어보고 차이를 확인하기\n",
    "- Visdom이라는 시각화 도구도 살펴볼 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15b7d2-479f-4618-bb93-a744d4218d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
