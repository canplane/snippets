{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25078a50-797a-43ed-9d09-f23c08c4d647",
   "metadata": {},
   "source": [
    "# Lab-03 Deeper Look at Gradient Descent\n",
    "- Hypothesis function 복습\n",
    "- 사용할 모의 data 확인\n",
    "- Cost function 이해\n",
    "- Gradient descent 이론\n",
    "- Gradient descent 구현\n",
    "- Gradient descent 구현 (nn.optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d002c01-12f5-4d5b-89b5-2054292ecd9a",
   "metadata": {},
   "source": [
    "## Hypothesis (Linear Regression)\n",
    "\n",
    "$H(x) = Wx + b$ (Weight $W$, Bias $b$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2598a943-be86-47aa-bd4b-390b417ceb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbdd986-9619-4e95-8a48-a928951a0679",
   "metadata": {},
   "source": [
    "## Simpler Hypothesis Function\n",
    "$H(x) = Wx$ (No Bias!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2082d10-eb88-493e-a6ec-e613e6b429f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "# b = torch.zeros(1, requires_grad=True)\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9b3bf-3dc9-48d0-ba52-24619c89b568",
   "metadata": {},
   "source": [
    "## What is the best model\n",
    "$H(x)=x$가 정확한 모델. $W=1$가 가장 좋은 숫자.\n",
    "\n",
    "어떻게 모델의 좋고 나쁨을 평가할 수 있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d145a22-a7f6-4bfb-a4cc-9684085f05e2",
   "metadata": {},
   "source": [
    "## Cost function: Intuition\n",
    "\n",
    "- $W=1$일 때 $cost=0$\n",
    "- $1$에서 멀어질수록 높아진다.\n",
    "\n",
    "Mean Squared Error (MSE) :\n",
    "$cost(W,b) = \\frac{1}{m} \\sum_{i=1}^{m} (H(x^{(i)}) - y^{(i)})^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37530e68-0882-4836-80fb-0377e235d1e2",
   "metadata": {},
   "source": [
    "## Gradient Descent: Intuition\n",
    "\n",
    "- 곡선을 내려가자.\n",
    "- 기울기가 클수록 더 멀리!\n",
    "- \"**Gradient**\"를 계산하자\n",
    "\n",
    "## Gradient Descent: The Math\n",
    "\n",
    "$\\frac{\\partial cost}{\\partial W} = \\nabla W$\n",
    "\n",
    "$\\nabla W = \\frac{\\partial cost}{\\partial W} = \\frac{2}{m} \\sum_{i=1}{m} (Wx^{(i)} - y^{(i)})x^{(i)}$\n",
    "\n",
    "$W := W - \\alpha \\nabla W$ : Gradient Descent (Gradient를 이용해 Cost를 줄인다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5085a-c5a3-4cba-ba03-cf53db004679",
   "metadata": {},
   "source": [
    "## Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "887576a3-6f77-46ac-80b0-35dac29755e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10 W: 0.000, Cost: 4.666667\n",
      "Epoch    1/10 W: 1.400, Cost: 0.746666\n",
      "Epoch    2/10 W: 0.840, Cost: 0.119467\n",
      "Epoch    3/10 W: 1.064, Cost: 0.019115\n",
      "Epoch    4/10 W: 0.974, Cost: 0.003058\n",
      "Epoch    5/10 W: 1.010, Cost: 0.000489\n",
      "Epoch    6/10 W: 0.996, Cost: 0.000078\n",
      "Epoch    7/10 W: 1.002, Cost: 0.000013\n",
      "Epoch    8/10 W: 0.999, Cost: 0.000002\n",
      "Epoch    9/10 W: 1.000, Cost: 0.000000\n",
      "Epoch   10/10 W: 1.000, Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1)\n",
    "# learning rate 설정\n",
    "lr = 0.1\n",
    "\n",
    "nb_epochs = 10\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W\n",
    "    \n",
    "    # cost gradient 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    gradient = torch.sum((W * x_train - y_train) * x_train)\n",
    "    \n",
    "    print(\"Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}\".format(epoch, nb_epochs, W.item(), cost.item()))\n",
    "    \n",
    "    # cost gradient로 H(x) 개선\n",
    "    W -= lr * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b3cd09-0899-4924-b4c2-1b530950e7ad",
   "metadata": {},
   "source": [
    "## Gradient Descent with `torch.optim`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8f12c-5024-435f-8d33-5e201c6a3958",
   "metadata": {},
   "source": [
    "```\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W], lr=0.15)\n",
    "\n",
    "# cost로 H(x) 개선\n",
    "optimizer.zero_grad()\n",
    "cost.backward()\n",
    "optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e6574d4-d4da-41c6-85b0-c543a3addfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10 W: 0.000, Cost: 4.666667\n",
      "Epoch    1/10 W: 1.400, Cost: 0.746667\n",
      "Epoch    2/10 W: 0.840, Cost: 0.119467\n",
      "Epoch    3/10 W: 1.064, Cost: 0.019115\n",
      "Epoch    4/10 W: 0.974, Cost: 0.003058\n",
      "Epoch    5/10 W: 1.010, Cost: 0.000489\n",
      "Epoch    6/10 W: 0.996, Cost: 0.000078\n",
      "Epoch    7/10 W: 1.002, Cost: 0.000013\n",
      "Epoch    8/10 W: 0.999, Cost: 0.000002\n",
      "Epoch    9/10 W: 1.000, Cost: 0.000000\n",
      "Epoch   10/10 W: 1.000, Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[1], [2], [3]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W], lr=0.15)\n",
    "\n",
    "nb_epochs = 10\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W\n",
    "    \n",
    "    # cost gradient 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "    \n",
    "    print(\"Epoch {:4d}/{} W: {:.3f}, Cost: {:.6f}\".format(epoch, nb_epochs, W.item(), cost.item()))\n",
    "    \n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78d4b6-b6a9-4f14-afa8-966efb4325a0",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "- 지금까지 하나의 정보로부터 추측하는 모델을 만들었습니다.\n",
    "    - 예시 1) 수업 참여도 -> 수업 점수\n",
    "    - 예시 2) 총 수면 시간 -> 집중력   \n",
    "- 하지만 대부분의 추측은 많은 정보를 추합해서 이뤄집니다.\n",
    "    - 예시 1) 쪽지 시험 성적들 -> 중간고사 성적\n",
    "    - 예시 2) 암의 위치, 넓이, 모양 -> 치료 성공률\n",
    "- 여러 개의 정보로부터 결론을 추측하는 모델은 어떻게 만들까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfcd965-d48b-41f4-8398-1da2e4ed45dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
