{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f19213-a00e-4733-9e8e-aef6202efedd",
   "metadata": {},
   "source": [
    "# Lab 10 Convolution\n",
    "\n",
    "- MNIST\n",
    "- PyTorch Visdom\n",
    "- PyTorch Datasets & Custom Dataset\n",
    "- CIFAR-10\n",
    "- VGG & ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3b71b-b6c5-4ad6-afc5-2dbc24f14f48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Convolution?\n",
    "\n",
    "- 이미지 위에서 stride 값 만큼 filter(kernel)을 이동시키면서 겹쳐지는 부분의 각 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 연산\n",
    "\n",
    "```\n",
    "1 2 3 0 1\n",
    "0 1 5 1 0     1 0 1    8 9 8\n",
    "1 0 2 2 1     0 1 0    8 5 9\n",
    "1 1 2 0 0     1 0 1    6 5 5\n",
    "1 0 1 1 1\n",
    "\n",
    "  input      filter   output\n",
    "```\n",
    " \n",
    "```\n",
    "output[0][0] =\n",
    "    (1x1) + (2x0) + (3x1) +\n",
    "    (0x0) + (1x1) + (5x0) +\n",
    "    (1x1) + (0x0) + (2x1) = 8\n",
    "```\n",
    "\n",
    "- stride : filter를 한 번에 얼마나 이동할 것인가\n",
    "- padding : zero-padding (zero-padding이 1이면 0 띠가 한 번 주위를 두른다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326cdaa9-8688-413a-bdfd-d52eeb56e42a",
   "metadata": {},
   "source": [
    "## PyTorch nn.Conv2d\n",
    "\n",
    "ex) 입력 채널 1 / 출력 채널 1 / 커널 크기 3x3\n",
    "\n",
    "$\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) + \\sum_{k=0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k) * \\text{input}(N_i, k)$\n",
    "\n",
    "(where $*$ is the valid 2D cross-correlation operator)\n",
    "\n",
    "`torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)`\n",
    "\n",
    "ex) `conv = nn.Conv2d(1, 1, 3)`\n",
    "\n",
    "만약 커널이 정 사이즈가 아니면 (1, 3) 같은 튜플로 넣으면 됨.\n",
    "\n",
    "\n",
    "## 입력의 형태\n",
    "\n",
    "- input type : torch.Tensor\n",
    "- input shape : (N x C x H x W) (batch_size, channel, height, width)\n",
    "\n",
    "## 직접 해볼까요?\n",
    "\n",
    "$\\text{output size} = \\frac{\\text{input size} - \\text{filter size} + (2 * \\text{padding})}{\\text{stride}} + 1$\n",
    "\n",
    "- 예제 1)\n",
    "    - input image size : 227x227\n",
    "    - filter size = 11x11\n",
    "    - stride = 4\n",
    "    - padding = 0\n",
    "    - **output image size = ?**\n",
    "- 예제 2)\n",
    "    - input image size : 64x64\n",
    "    - filter size = 7x7\n",
    "    - stride = 2\n",
    "    - padding = 0\n",
    "    - **output image size = ?**\n",
    "- 예제 3)\n",
    "    - input image size : 32x32\n",
    "    - filter size = 5x5\n",
    "    - stride = 1\n",
    "    - padding = 2\n",
    "    - **output image size = ?**\n",
    "- 예제 4)\n",
    "    - input image size : 32x64\n",
    "    - filter size = 5x5\n",
    "    - stride = 1\n",
    "    - padding = 0\n",
    "    - **output image size = ?**\n",
    "- 예제 5)\n",
    "    - input image size : 64x32\n",
    "    - filter size = 3x3\n",
    "    - stride = 1\n",
    "    - padding = 1\n",
    "    - **output image size = ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b785119e-de0d-4ea7-b7cd-84d83bdf4f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 55, 55])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = nn.Conv2d(1, 1, 11, stride=4, padding=0)\n",
    "conv            # Conv2d(1, 1, kernel_size=(11, 11), stride=(4, 4))\n",
    "\n",
    "inputs = torch.Tensor(1, 1, 227, 227)\n",
    "inputs.shape    # torch.Size([1, 1, 227, 227])\n",
    "\n",
    "out = conv(inputs)\n",
    "out.shape       # torch.Size([1, 1, 55, 55])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be793cc-2622-49b7-8454-77bd546653c0",
   "metadata": {},
   "source": [
    "## Neuron과 Convolution\n",
    "\n",
    "- Perceptron과 Convolution\n",
    "\n",
    "```\n",
    "   1 1\n",
    "  2 0 \\\n",
    " 3 1 \\\n",
    " 0 0 -\n",
    " 1 1 - Perceptron   - 8 (1 + 3 + 1 + 1 + 2)\n",
    " 5 0 -\n",
    " 1 1 /     |\n",
    "  0 0 /\n",
    "   2 1    bias\n",
    "```\n",
    "(첫 번째는 input, 두 번째는 weight)\n",
    "\n",
    "\n",
    "## Pooling\n",
    "이미지 사이즈 줄이기 위해서 사용할 수도 있고, fully-connected 연산을 대체하기 위해 average pooling을 사용하기도 함.\n",
    "\n",
    "- Max Pooling\n",
    "    ```\n",
    "    1 9 3 7\n",
    "    4 5 2 8  ->  9 8\n",
    "    7 3 9 0      7 9\n",
    "    1 2 3 3\n",
    "    ```\n",
    "\n",
    "- Average Pooling\n",
    "    ```\n",
    "    1 1 2 2\n",
    "    1 1 2 2  ->  1 2\n",
    "    3 3 1 2      3 2\n",
    "    3 3 1 4\n",
    "    ```\n",
    "\n",
    "`torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8e683e-afde-4cfc-b9df-0fffa0579664",
   "metadata": {},
   "source": [
    "## CNN implementation\n",
    "\n",
    "![snapshot](./10-1-0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5d9809-49d7-4827-a11c-5735d7f331d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 12, 12])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.Tensor(1, 1, 28, 28)\n",
    "conv1 = nn.Conv2d(1, 5, 5)\n",
    "pool = nn.MaxPool2d(2)\n",
    "out = conv1(input)\n",
    "out2 = pool(out)\n",
    "out.size()     # torch.Size([1, 5, 24, 24])\n",
    "out2.size()    # torch.Size([1, 5, 12, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcd395-c629-4ad7-ba6e-ef7127c591b9",
   "metadata": {},
   "source": [
    "## What's Next?\n",
    "\n",
    "- 오늘은 Convolution 연산과 Pooling 연산을 배우고 직접 활용해봤습니다.\n",
    "- 다음 시간에는 MNIST dataset에 CNN을 적용해보도록 하겠습니다.\n",
    "\n",
    "## One More Thing!\n",
    "굳이 공부할 필요는 없는 것.\n",
    "\n",
    "**cross-correlation ($*$)가 뭐냐?**\n",
    "\n",
    "![snapshot](./10-1-1.png)\n",
    "\n",
    "- convolution은, 이 친구가 filter라 생각해봤을 때, 필터 값이 기존의 이미지와 얼마나 겹치는가에 해당하는 걸로 출력 값 결정.\n",
    "- cross-correlation은, g 값을 뒤집지 않고 그대로 집어 넣음.\n",
    "\n",
    "### Cross-correlation\n",
    "\n",
    "- Cross-correlation과 Convolution의 차이를 간단히 말하면...?\n",
    "\n",
    "- 뒤집고 계산하면 => (Convolution)\n",
    "- 안 뒤집고 계산하면 => (Cross-Correlation)\n",
    "\n",
    "- 안 뒤집고 계산해서 Cross-Correlation!\n",
    "\n",
    "실제로 딥러닝 공부하면서는 cross-correlation과 convolution에 대해서 크게 고민을 할 필요는 없기 때문에 one more thing이라 넣어둔 것. 몰라도 무방하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67b7c46-35c6-4619-8dcf-1f44afb76396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
