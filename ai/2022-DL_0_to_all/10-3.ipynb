{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56461ab7-72b8-4c5e-a986-3f4d1f082ef9",
   "metadata": {},
   "source": [
    "# Lab-10-3 Visdom\n",
    "\n",
    "## 지난시간까지\n",
    "- MNIST-CNN\n",
    "\n",
    "## 오늘은\n",
    "- Visdom사용법을 익히고 MNIST-CNN 학습에 적용해보자.\n",
    "\n",
    "## Visdom 설치\n",
    "`pip install visdom`\n",
    "\n",
    "## Visdom 서버 켜기\n",
    "`python -m visdom.server`\n",
    "\n",
    "이러면 `http://localhost:8097`에 열려 있다는 메시지 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29440d6-cafa-4543-9d8f-057a851eb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785cb87c-0540-4bb8-94d6-c10eb8282dcf",
   "metadata": {},
   "source": [
    "## visdom 사용법으로 이번에 배울 것\n",
    "- Text\n",
    "- image\n",
    "- images\n",
    "- Line plot\n",
    "\n",
    "## 지금부터\n",
    "- visdom을 사용법을 익히고 MNIST-CNN loss graph까지 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644dd2f5-4acb-4052-9114-b49140afd5d7",
   "metadata": {},
   "source": [
    "### 10-3-1 Visdom Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6ed6be-fe58-41b8-b64d-ea1c70f15736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c18ab40-c11a-42af-ac5f-00965c88d378",
   "metadata": {},
   "source": [
    "### import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee77249b-d047-4bc5-88a6-4efabb9e5b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import visdom\n",
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa24ec-0b7e-44e7-9458-e39c7ef53edd",
   "metadata": {},
   "source": [
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb69d56-8ef9-4fa7-a448-ac0e69043238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_3b51072d11ab70'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.text(\"Hello, world!\", env=\"main\")\n",
    "# env=\"main\"은 있어도 되고 없어도 되는데, 나중에 한번에 모든 창 끌 때 사용할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd593866-3654-4610-9476-bf523804b645",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0edadab3-db2c-4420-b4b8-c28f64010aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_3b51072e167b16'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 200, 200)  # 3으로 하면 rgb로 잡히고, 200x200\n",
    "vis.image(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75f6ce-c3a7-4844-8c5c-cd45dfafad84",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddcda80-ce5e-4873-b975-4782ac265de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_3b51072ef3d308'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.images(torch.Tensor(3, 3, 28, 28))\n",
    "# image 3개 띄워진 것 볼 수 있음. 28x28 이미지 3개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6874e14-c173-4885-86de-ac4459946f79",
   "metadata": {},
   "source": [
    "### example (using MNIST and CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7e066d-b93d-4261-b714-68c67b56f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "MNIST = dsets.MNIST(root=\"./MNIST_data\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "cifar10 = dsets.CIFAR10(root=\"./cifar10\", train=True, transform=torchvision.transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf1b83-48d4-4a7c-b29c-a0834018cb62",
   "metadata": {},
   "source": [
    "#### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630542bc-bc08-4924-9c0d-153042570f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_3b510730bfe896'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cifar10.__getitem__(0)  # cifar10의 첫번째 데이터 가져옴\n",
    "print(data[0].shape)           # [3, 32, 32] : 3채널(rgb) 32x32 그림\n",
    "vis.images(data[0], env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3139964-2f83-48ee-9b42-daa2ca0deb23",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c0f1c3-3910-4150-aff4-c51199d95477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_3b51073170fbec'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = MNIST.__getitem__(0)\n",
    "print(data[0].shape)          # [1, 28, 28] : 1채널(gray) 28x28 그림\n",
    "vis.images(data[0], env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27e8c3e-3197-45ad-81e5-b0f3e8854b99",
   "metadata": {},
   "source": [
    "#### Check dataset\n",
    "데이터 한 번에 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d2d99a-04c1-43ce-8529-034b29a80064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=MNIST,\n",
    "                                         batch_size=32,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1741629-1abc-4b64-ab9c-8bbb1bd147f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for num, value in enumerate(data_loader):\n",
    "    value = value[0]\n",
    "    print(value.shape)   # [32, 1, 28, 28] : 1채널 28x28 이미지 32개\n",
    "    vis.images(value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92c4ca8-e61b-4caf-a5fd-453c04ea2d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.close(env=\"main\")   # main인 애들 다 꺼줘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b34f79-3504-4eb4-b3c3-8f8ced78a790",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Line Plot\n",
    "\n",
    "학습을 진행하면서 loss가 어떻게 되고 있는지를 그래프로 보고 싶을 수 있음. 그래프로 표현하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fd4721d-f051-4f05-bb08-ad0ad5c84648",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = torch.randn(5)\n",
    "# 원소 5개짜리 리스트. X 값을 넣지 않으면 x축 값은 무조건 0부터 1까지의 값으로만 선언이 된다.\n",
    "plt = vis.line(Y=Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63bb60a-c699-4823-811b-de21dfa09c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = torch.Tensor([1, 2, 3, 4, 5])\n",
    "# x 값을 넣어주면 x축 값이 1, 2, 3, 4, 5 이런 식으로 그대로 들어감.\n",
    "plt = vis.line(Y=Y_data, X=X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27e25ef-3b45-4944-805c-54a95dc0f6d0",
   "metadata": {},
   "source": [
    "#### Line update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cc303d3-5c44-48b4-8c19-40dac6d4744a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_3b510735ac3258'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_append = torch.randn(1)\n",
    "X_append = torch.Tensor([6])\n",
    "\n",
    "vis.line(Y=Y_append, X=X_append, win=plt, update=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe3b08-b47b-4b16-8cb6-be15c828e1cb",
   "metadata": {},
   "source": [
    "#### multiple Line on single windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344f590f-4f57-467a-9b8f-539c775d77c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "num = torch.Tensor(list(range(0, 10)))\n",
    "print(num.shape)\n",
    "num = num.view(-1, 1)\n",
    "print(num.shape)\n",
    "num = torch.cat((num, num), dim=1)\n",
    "print(num.shape)\n",
    "\n",
    "plt = vis.line(Y=torch.randn(10, 2), X=num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba46f2b-32d9-4fc3-b0d7-7ec9165718d1",
   "metadata": {},
   "source": [
    "#### Line info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9823d3fe-211c-4cf5-968c-417033aeaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=Y_data, X=X_data, opts=dict(title=\"Test\", showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40023e39-c867-4a2e-8a9b-0732ed6c3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=Y_data, X=X_data, opts=dict(title=\"Test\", legend=[\"1번\"], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20d99226-453b-442c-94b3-0a7fb02bc3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=torch.randn(10, 2), X=num, opts=dict(title=\"Test\", legend=[\"1번\", \"2번\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023a9748-a7f7-4a6c-9bd1-aa1acd4fefd9",
   "metadata": {},
   "source": [
    "#### make function for update line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3a0380-248c-4e49-8746-871067cef639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=loss_value,\n",
    "             win=loss_plot,\n",
    "             update=\"append\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24665d70-7e95-4eee-8e7a-086f18d80033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = vis.line(Y=torch.Tensor(1).zero_())\n",
    "\n",
    "for i in range(500):\n",
    "    loss = torch.randn(1) * i\n",
    "    loss_tracker(plt, loss, torch.Tensor([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8848f72-d719-46f1-95a8-42947773c90d",
   "metadata": {},
   "source": [
    "#### close the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c639655d-c743-4fd8-90c3-df1e7b5a05ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165730c-5350-4738-96e5-c44ccf6cf388",
   "metadata": {},
   "source": [
    "이 외에도 엄청 많은 기능들이 있다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c59c93-b333-44ad-bed0-58158d543889",
   "metadata": {},
   "source": [
    "### 10-3 MNIST-CNN with Visdom\n",
    "\n",
    "10-2 할 때랑 똑같은 코드인데 visdom만 넣은 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "007cd84d-4191-4676-971e-ab8cd8257c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5035171-9ab3-47d0-9858-c2b483a6d5d6",
   "metadata": {},
   "source": [
    "#### import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "769c8778-441e-446b-88c8-20e767600016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cc1a0-4271-45f9-823c-3d0fb531ce0a",
   "metadata": {},
   "source": [
    "#### define loss_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58c61bee-3d2c-46db-9030-a0f2eb87e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "            Y=loss_value,\n",
    "            win=loss_plot,\n",
    "            update=\"append\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f745d02-eb9f-4838-a4ad-b2e9aa0c69b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9912034a-4728-4675-8bb3-4560d1649e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdee218c-1620-40b4-b968-9d84a99da053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST dataset\n",
    "\n",
    "mnist_train = dsets.MNIST(root=\"MNIST_data/\",\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root=\"MNIST_data/\",\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebde7de1-d7be-4f1f-953a-65809c1e71eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f401456-6abe-4145-855f-34b7f7002663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(3*3*128, 625)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(625, 10, bias=True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b017bf6d-6e6a-4bc4-9fe8-91db46d483ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:53] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "value = (torch.Tensor(1, 1, 28, 28)).to(device)\n",
    "print( (model(value)).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d135c1d1-ab70-4482-8c2b-940c46c83e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f0e5c-8db5-44b4-a962-321a9b878cb3",
   "metadata": {},
   "source": [
    "#### make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9e0742b-68cf-4a81-a662-b0c0731006a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(), opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b916f-f6e7-4ebf-b1b1-ba10e6088fd1",
   "metadata": {},
   "source": [
    "#### train with loss_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9714d72a-8408-4616-925e-040fc5fc4038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoth:1] cost = 0.1293681412935257\n",
      "[Epoth:2] cost = 0.04197239503264427\n",
      "[Epoth:3] cost = 0.029367033392190933\n",
      "[Epoth:4] cost = 0.02299959398806095\n",
      "[Epoth:5] cost = 0.01744411513209343\n",
      "[Epoth:6] cost = 0.014136048033833504\n",
      "[Epoth:7] cost = 0.01292012445628643\n",
      "[Epoth:8] cost = 0.011273977346718311\n",
      "[Epoth:9] cost = 0.009665490128099918\n",
      "[Epoth:10] cost = 0.007492149714380503\n",
      "[Epoth:11] cost = 0.009115600027143955\n",
      "[Epoth:12] cost = 0.0069937133230268955\n",
      "[Epoth:13] cost = 0.008123529143631458\n",
      "[Epoth:14] cost = 0.006831460632383823\n",
      "[Epoth:15] cost = 0.007010275032371283\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        \n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "    \n",
    "    print('[Epoth:{}] cost = {}'.format(epoch+1, avg_cost))\n",
    "    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch]))\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4ed4b-3079-4058-8e8d-41bd821f7a94",
   "metadata": {},
   "source": [
    "![snapshot](./10-3-0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d6ee1ac-e85d-45b1-844e-0d159cbe7fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sanghoon/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/Users/sanghoon/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9733999967575073\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd86566-0195-4662-b69d-1b826eca8492",
   "metadata": {},
   "source": [
    "### 오늘 같이 해본 것들은?\n",
    "- Visdom 사용법\n",
    "- 실제 학습에 적용해보기\n",
    "\n",
    "### What's Next?\n",
    "- 내가 가진 사진을 이용해서 학습을 해볼 수 없을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827aa03-3808-4861-b047-26bab326aac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
